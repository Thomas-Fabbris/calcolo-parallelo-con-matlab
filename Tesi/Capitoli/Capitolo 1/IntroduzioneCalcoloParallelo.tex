\nocite{Patterson2022}
L'idea alla base del calcolo parallelo \'e che gli utenti di un qualsiasi sistema di elaborazione possono avere a disposizione tanti processori
quanti ne desiderano, per poi interconnetterli a formare un sistema
multiprocessore, le cui prestazioni sono, con buona approssimazione,
proporzionali al numero di processori impiegati.

La sostituzione di un singolo processore caratterizzato da un'elevata
capacit\'a di calcolo, tipicamente presente nelle architetture dei sistemi
\textit{mainframe}, con un insieme di processori pi\'u efficienti
dal punto di vista energetico permette di raggiungere migliori prestazioni
per unit\'a di energia, a condizione che i programmi eseguiti siano
appositamente progettati per essere eseguiti su hardware parallelo; approfondiremo questi aspetti nei paragrafi \ref{par1.2} e \ref{par1.3}.

Una tendenza introdotta da IBM nel 2001 nell'ambito della progettazione di sistemi paralleli \cite{Tendler2001} è il raggruppamento
di diverse unit\'a di calcolo all'interno di un singolo circuito integrato; in questo contesto, i processori montati su un singolo \textit{chip} di silicio vengono chiamati \textit{core}.\newline
Il microprocessore \textit{multicore} risultante appare al sistema operativo in esecuzione sull'elaboratore come l'insieme di $N$ processori, ciascuno dotato di un set di registri e di una memoria \textit{cache} dedicati; solitamente i microprocessori \textit{multicore} sono impiegati in sistemi a memoria condivisa, in cui i \textit{core} condividono lo stesso spazio di indirizzamento fisico.\newline
Il funzionamento di questa categoria di sistemi multiprocessore si basa sul parallelismo a livello di attività (o a livello di processo): più
processori sono impiegati per svolgere diverse attivit\'a simultaneamente e ciascuna attivit\'a corrisponde a un'applicazione a singolo
\textit{thread}.\newline
In generale, ogni \textit{thread} esegue un'operazione ben definita e \textit{thread} differenti possono agire sugli stessi
dati o su insiemi di dati diversi, garantendo un elevato \textit{throughput} per attivit\'a tra loro indipendenti.

D'altro canto, tutte le applicazioni che richiedono un utilizzo intensivo di risorse computazionali, diffuse non pi\'u solamente in ambito
scientifico, possono essere eseguite solo su \textit{cluster} di elaboratori, una tipologia di sistemi multiprocessore che si differenzia dai microprocessori \textit{multicore} per il fatto di essere costituita da un insieme di calcolatori completi, chiamati nodi, collegati tra loro per mezzo di una rete LAN (\textit{Local Area Network}).\newline
In ogni caso, il funzionamento di un sistema di elaborazione parallelo si basa sull'uso congiunto di processori distinti.\newline
Per sfruttare al meglio le potenzialit\'a offerte dai \textit{cluster} di elaboratori, i programmatori di applicazioni devono sviluppare programmi a esecuzione parallela efficienti e scalabili a seconda del numero di processori disponibili durante l'esecuzione; risulta necessario applicare un parallelismo a livello di dati, che prevede la distribuzione dell'insieme dei dati in input tra le CPU del \textit{cluster}, per poi far eseguire la medesima operazione, su sottoinsiemi distinti di dati, a ogni processore.

Una tipica operazione parallelizzabile a livello di dati è la somma vettoriale perch\'e le componenti del vettore risultante vengono ottenute
sommando solamente le componenti omologhe dei due vettori di partenza; possiamo intuire fin da subito che una condizione necessaria per la parallelizzazione di un qualsiasi algoritmo è l'indipendenza tra le operazioni eseguite ad un certo passo dell'esecuzione.\newline
Per esempio, supponiamo di dover sommare due vettori di numeri reali di dimensione $N$ avvalendoci di un sistema \textit{dual-core}, ossia di un sistema di elaborazione dotato di un microprocessore che contiene al suo interno
due \textit{core}.\newline
Sarebbe conveniente avviare un thread separato su ogni \textit{core}, specializzato nella somma di due componenti omologhe dei vettori operandi; attraverso un'attenta distribuzione dei dati in input, il \textit{thread} in esecuzione sul primo \textit{core} sommerebbe le componenti da $1$ a $\left\lceil\frac{N}{2}\right\rceil$ dei vettori di partenza,
e al contempo il secondo \textit{core} si occuperebbe della somma delle componenti da $\left\lceil\frac{N}{2}\right\rceil + 1$ a $N$.

In realtà, la rigida distinzione proposta tra parallelismo a livello di attivit\'a e parallelismo a livello di dati non trova un diretto
riscontro nella realt\'a, in quanto sono comuni programmi applicativi che sfruttano entrambi gli approcci al fine di massimizzare le prestazioni.

Cogliamo l'occasione per precisare la terminologia, in parte gi\'a utilizzata, per descrivere la componente hardware e la componente software di un generico calcolatore: l'hardware, riferendoci con questo termine esclusivamente al processore, pu\'o essere seriale, come nel caso di un processore \textit{single core}, o parallelo, come nel caso di un processore \textit{multicore}, mentre il software viene detto sequenziale o concorrente, a seconda della presenza di processi cooperanti la cui esecuzione viene influenzata dagli altri processi presenti nel sistema.\newline
Naturalmente, un programma concorrente pu\'o essere eseguito sia su hardware seriale che su hardware parallelo.\newline
Infine, con il termine programma a esecuzione parallela, o pi\'u semplicemente software parallelo, indichiamo un programma, sequenziale o concorrente, eseguito su hardware parallelo.