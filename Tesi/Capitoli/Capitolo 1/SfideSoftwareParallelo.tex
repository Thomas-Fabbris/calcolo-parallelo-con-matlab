%!TeX root = ../../Tesi.tex
Le motivazioni che rendono lo sviluppo di programmi a esecuzione parallela una vera e propria sfida per i programmatori
di applicazioni sono molteplici e appartengono a diverse aree di intervento.

Innanzitutto, una caratteristica contraddistintiva del software parallelo
\`e la scalabilit\`a, ovvero la capacit\`a del sistema software di incrementare le proprie prestazioni in funzione della potenza
di calcolo richiesta in un preciso istante e di adeguare di riflesso le risorse di calcolo impiegate \cite{Michael2007}.\newline
Da un lato, la scalabilit\`a, sfruttando la sinergia tra hardware e software di un sistema informatico, consente di ottenere
sistemi multiprocessore tolleranti ai guasti e a elevata disponibilit\`a, ma dall'altro richiede che il software venga progettato
in maniera tale da sfruttare al meglio i diversi processori e che il codice sorgente sia riscritto a ogni
incremento del numero di unit\`a di elaborazione.

La profonda ristrutturazione richiesta durante il ciclo di vita di tutti i  programmi a elaborazione parallela, radicata sia nella
fase di \textit{design} che durante la fase di manutenzione, \`e necessaria per il raggiungimento delle massime prestazioni, nonostante rallenti l'introduzione di nuove funzionalit\`a.

A questo proposito, la programmazione parallela \`e per definizione ad alte prestazioni ed esige una
velocit\`a di esecuzione elevata; in caso contrario, sarebbe sufficiente disporre di programmi sequenziali eseguiti su sistemi monoprocessore, la cui programmazione \`e di gran lunga pi\`u agevole.

Come abbiamo accennato nel paragrafo \ref{par:introduzioneCalcoloParallelo}, le attivit\`a, chiamate \textit{task}, in cui \`e ripartito un \textit{job} svolto da un
programma a esecuzione parallela devono essere indipendenti le une dalle altre per poter essere eseguite su pi\`u processori simultaneamente.\newline
Di conseguenza, \`e consigliato suddividere l'applicazione in maniera tale che ogni processore compi circa lo stesso carico di lavoro in intervalli
di tempo di durata comparabile; se un processore impiegasse un tempo maggiore per terminare le \textit{task} a esso assegnate rispetto agli altri, i benefici prestazionali portati
dall'impiego di sistemi multiprocessore svanirebbero.

Oltre allo \textit{scheduling} delle attivit\`a e al bilanciamento del carico di lavoro tra i processori, altri problemi derivano dalla presenza di
\textit{overhead} di comunicazione e di sincronizzazione tra le diverse unit\`a di lavoro, qualora si rendesse necessaria la cooperazione tra le
\textit{task} per portare a termine il compito dato.

Una regola generale per gestire queste problematiche \`e evitare di sprecare la maggior parte del tempo di esecuzione di un software parallelo
per la comunicazione e la sincronizzazione tra i processori, dedicando idealmente un lasso di tempo irrilevante a questi due aspetti.

Chiaramente, le difficolt\'a incontrate nella realizzazione di programmi a esecuzione parallela vanno di pari passo con il numero
di processori presenti nel sistema.

Un'ulteriore sfida da affrontare durante la progettazione di programmi eseguiti su pi\`u processori simultaneamente \`e descritta dalla legge di
Amdahl, che limita il miglioramento prestazionale complessivamente ottenuto dall'ottimizzazione di una singola parte di un sistema di
elaborazione.
\subsection{La legge di Amdahl}
La legge di Amdahl, esposta per la prima volta dall’ingegnere statunitense Gene Myron Amdahl al AFIPS \textit{Spring Joint Computer
    Conference} del 1967, \`e una legge empirica, reputata un'espressione quantitativa dalla legge dei rendimenti decrescenti dell’economista classico David Ricardo.

Amdahl utilizza il termine \textit{enhancement} per indicare un qualsiasi miglioramento introdotto in un sistema di
elaborazione.\newline
Il beneficio, in termini di prestazioni, attribuibile a esso dipende da due fattori: la frazione del tempo di esecuzione iniziale,
che diminuisce a seguito dell'\textit{enhancement}, e l'entit\`a del miglioramento.\newline
In aggiunta, il concetto di incremento di velocit\`a, o \textit{speedup}, ricopre un ruolo centrale nell'intero impianto teorico.

Dato un generico programma e un calcolatore a cui viene apportato un \textit{enhancement}, denominato calcolatore migliorato,
lo \textit{speedup} \`e definito come il fattore secondo il quale il calcolatore migliorato riesce ad eseguire più
velocemente il programma rispetto al calcolatore originale.\newline
Questa indicazione dell'incremento di prestazioni viene calcolata secondo la seguente formula
\[
    Speedup=\frac{Performance\ programma\ con\ miglioramento}{Performance\ programma\ senza\ miglioramento}
\]
sotto l’ipotesi in cui le prestazioni del calcolatore migliorato siano effettivamente misurabili attraverso le metriche
prestazionali scelte.

Il tempo di esecuzione per il calcolatore migliorato, denotato $T_{dopo}$, pu\`o essere espresso come somma
del tempo di esecuzione modificato dal miglioramento, $T_{modificato}$, e di quello non interessato dal cambiamento,
$T_{nonModificato}$.
\begin{equation} \label{eq:tDopo}
    T_{dopo}=\frac{T_{modificato}}{Entit\grave{a}~miglioramento} + T_{nonModificato}
\end{equation}

Possiamo riformulare la legge di Amdahl in termini di incremento di velocit\`a rispetto al tempo di esecuzione iniziale.
\begin{equation} \label{eq:speedup}
    \mathit{Speedup}=\frac{T_{dopo}}{T_{prima}-T_{dopo}}+\frac{T_{dopo}}{Entit\grave{a}~miglioramento}
\end{equation}
con $T_{prima}$ tempo di esecuzione prima del miglioramento.

La formula precedente viene comunemente riscritta ponendo pari a $1$ il tempo di esecuzione prima dell'\textit{enhancement} ed esprimendo
il tempo modificato dal miglioramento come frazione del tempo originario di esecuzione, ottenendo
\[
    \mathit{Speedup} = \frac{1}{1 - \mathit{Frazione~tempo~modificato} + \frac{\mathit{Frazione~tempo~modificato}}{\mathit{Entit\grave{a}~miglioramento}}}
\]

Come \`e intuibile, la legge di Amdahl pu\`o essere applicata alla stima quantitativa del miglioramento delle
prestazioni solo se il tempo in cui viene sfruttata una certa funzione all'interno del sistema \`e noto, cos\`i come il
suo potenziale \textit{speedup}.

Un adattamento della legge di Amdahl al calcolo parallelo è il seguente:

\blockquote{Anche le pi\`u piccole parti di un programma devono essere rese parallele se si vuole eseguire il programma in modo efficiente su un sistema multiprocessore}.

\subsection{Verso i problemi \enquote{massicciamente paralleli}}
Nel contesto del calcolo parallelo, vengono usati termini specifici per contraddistinguere classi di problemi da risolvere.\newline
A titolo di esempio, un problema \enquote{\textit{embarrassingly parallel}} \`e un problema che richiede un minimo sforzo per essere suddiviso in un insieme di
\textit{task} indipendenti, a causa del loro debole accoppiamento \cite{Herlihy2012}, mentre il termine \enquote{\textit{massively parallel}}, in italiano \enquote{massicciamente parallelo},
descrive i problemi di grandi dimensioni suddivisibili in un numero elevato di \textit{task} eseguite simultaneamente su migliaia di processori.

Un problema \enquote{\textit{embarrassingly parallel}}, di particolare interesse per l'analisi numerica, \`e il calcolo approssimato di integrali definiti per
funzioni di una o pi\`u variabili; diversamente, il processo di addestramento di modelli avanzati di \textit{machine learning}, come le
\textit{deep neural network}, richiede l'esecuzione di migliaia di operazioni aritmetiche, inserendolo di diritto all'interno della classe dei problemi
\enquote{\textit{massively parallel}}.

Di seguito, effettuiamo una semplice analisi prestazionale di un problema di grandi dimensioni per studiare da vicino le insidie che si nascondono  nella distribuzione e nell'esecuzione di software parallelo su sistemi reali.

\begin{esempio}[Analisi prestazionale di un problema di grandi dimensioni]
    \label{esempio:analisiGrandiDimensioni}
    Supponiamo di sommare trenta variabili scalari e due matrici quadrate di dimensione \numproduct{3000 x 3000} servendoci dapprima di un tradizionale sistema
    monoprocessore e, successivamente, di un sistema multiprocessore con $30$ CPU che supporta la parallelizzazione della somma tra matrici. \newline
    Vogliamo analizzare la variazione delle prestazioni dei due sistemi quando:
    \begin{enumerate}[label=\alph*),noitemsep]
        \item il numero di processori del sistema multiprocessore aumenta a $120$;\label{item:primoAnalisiGrandiDimensioni}
        \item le matrici diventano di dimensione \numproduct{6000 x 6000}.\label{item:ultimoAnalisiGrandiDimensioni}
    \end{enumerate}
    La tabella \ref{tab:RisultatiAnalisiGrandiDimensioni} riporta la frazione dello \textit{speedup} potenziale raggiunta nei quattro possibili scenari di esecuzione, calcolata applicando le formule \eqref{eq:tDopo} e \eqref{eq:speedup}.

    \begin{table}[htbp]
    \centering
    \renewcommand{\arraystretch}{1.2}
   \begin{tabular}{@{} l r r @{}}
        \toprule
        {Dim. matrice} & \multicolumn{2}{c}{Num. processori} \\
        \cmidrule(l){2-3}
        & \multicolumn{1}{c}{30} & \multicolumn{1}{c}{120} \\
        \midrule
        \numproduct{3000 x 3000} & \num{0.7770} & \num{0.4727} \\
        \numproduct{6000 x 6000} & \num{0.8739} & \num{0.6375} \\
        \bottomrule
    \end{tabular}
    \caption{Frazione dello \textit{speedup} potenziale nei casi proposti dall'esempio \ref{esempio:analisiGrandiDimensioni}.}
    \label{tab:RisultatiAnalisiGrandiDimensioni}
\end{table}
\end{esempio}

L'esempio \ref{esempio:analisiGrandiDimensioni} evidenzia il problema fondamentale del calcolo parallelo: aumentare la velocit\`a di esecuzione
di un programma a esecuzione parallela su un sistema multiprocessore mantenendo fisse le dimensioni del problema \`e pi\`u difficile rispetto a migliorare
le prestazioni incrementando le dimensioni del problema proporzionalmente al numero di unit\`a di calcolo montate nel sistema.

Questo particolare comportamento porta alla definizione dei concetti di scalabilit\`a forte e di scalabilit\`a debole.\newline
La prima si riferisce all'incremento della velocit\`a di esecuzione che si ottiene in un sistema multiprocessore senza aumentare la dimensione del problema da
risolvere, mentre la seconda descrive l'incremento di velocit\`a ottenuto quando la dimensione del problema viene aumentata proporzionalmente al numero
di processori.

Possiamo giustificare il comportamento descritto in precedenza prendendo come modelli un qualsiasi sistema multiprocessore e un programma a esecuzione parallela.\newline
Indichiamo con $P > 1$ il numero di processori presenti nel
sistema e denotiamo con $M$ la dimensione del problema risolto dal programma\footnote{Per semplicit\`a possiamo pensare a $M$ come la dimensione dello spazio da allocare in memoria centrale per la
    risoluzione del problema.}.\newline
Sotto queste ipotesi, ogni processore possieder\`a uno spazio di memoria dedicato pari a $M$ nel caso della scalabilit\`a debole e pari a $\frac{M}{P}$ nel
caso della scalabilit\`a forte.

Potremmo essere erroneamente indotti a pensare che la scalabilit\`a debole sia pi\`u facilmente ottenibile rispetto alla scalabilit\`a forte, data la maggiore quantit\`a di memoria disponibile per ogni CPU, ma a seconda
del contesto applicativo considerato possiamo individuare validi motivi a supporto di ciascuno dei due approcci.\newline
In linea di massima, problemi di grandi
dimensioni richiedono moli di dati in input, rendendo la scalabilit\`a debole pi\`u agevole da raggiungere.

Quest'ultimo esempio chiarisce l'importanza del bilanciamento del carico.

\begin{esempio}[Bilanciamento del carico per un problema di grandi dimensioni]
    \label{esempio:bilanciamentoCarico}
    Per ottenere un aumento di velocit\`a di \num{75.4} volte per il problema di grandi dimensioni considerato nel caso \ref{item:ultimoAnalisiGrandiDimensioni}
    dell'esempio \ref{esempio:analisiGrandiDimensioni}, abbiamo implicitamente supposto che il carico fosse perfettamente bilanciato tra i $120$ processori del sistema.\newline
    Ora vogliamo determinare l'impatto sulle prestazioni nel caso in cui a uno dei processori viene assegnato:
    \begin{enumerate}[noitemsep]
        \item il \num{2.5}\% del carico totale, ovvero 150 addizioni;\label{item:primoBilanciamentoCarico}
        \item il \num{12.5}\% del carico totale, ovvero 750 addizioni.\label{item:ultimoBilanciamentoCarico}
    \end{enumerate}
    La tabella \ref{tab:RisultatiBilanciamentoCarico} riporta lo \textit{speedup} ottenuto nei due scenari ipotizzati e la rispettiva variazione percentuale calcolata con riferimento alla situazione ideale che presenta un carico perfettamente bilanciato.
    \begin{table}[htbp]
        \centering
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{@{} lrr N N @{}}
            \toprule
            {}                  & {150 addizioni} & {750 addizioni} \\
            \midrule
            \textit{Speedup}    & \num{33.50}           & \num{7.73}            \\
            $\Delta\%_{ideale}$ & \num{-55.57}          & \num{-89.74}          \\
            \bottomrule
        \end{tabular}
        \caption{\textit{Speedup} e sua variazione percentuale nei casi proposti dall'esempio \ref{esempio:bilanciamentoCarico}.}
        \label{tab:RisultatiBilanciamentoCarico}
    \end{table}
    L'importanza di suddividere equamente il carico di lavoro tra i processori del sistema \'e evidente dalla variazione in diminuzione dello \textit{speedup} registrata in entrambi gli scenari di utilizzo. \newline
    Una distribuzione non corretta delle attivit\`a da eseguire porta a una minore efficienza del sistema con intervalli di tempo non trascurabili in cui la maggioranza delle unit\`a di elaborazione \`e a riposo, attendendo che i processori in sovraccarico terminino il loro lavoro.
\end{esempio}